{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.02203020e+11 -3.71234895e-01 -1.82290829e-01  4.67186637e-01\n",
      "  1.01918354e+00 -6.87992098e-01 -6.19412766e-01]\n",
      "[ 2.02203020e+11 -3.71234895e-01 -1.82290829e-01 -2.05171200e-01\n",
      " -1.81782672e+00 -5.44670831e-01 -4.64932963e-01]\n",
      "[ 2.02203020e+11 -1.15025484e+00 -1.19261655e+00 -2.72406984e-01\n",
      "  7.35134518e-02 -6.64302632e-01 -5.90265633e-01]\n",
      "[ 2.02203020e+11 -1.15025484e+00 -1.82290829e-01 -4.74114335e-01\n",
      "  7.35134518e-02 -6.57195793e-01 -5.93180347e-01]\n",
      "[ 2.02203020e+11 -3.71234895e-01  8.28034889e-01 -4.74114335e-01\n",
      "  3.88736813e-01 -6.83254205e-01 -6.10668626e-01]\n",
      "[ 2.02203020e+11  1.18680499e+00  1.33319775e+00  8.70601339e-01\n",
      " -2.41709910e-01 -6.06263442e-01 -5.26141942e-01]\n",
      "[ 2.02203020e+11 -3.71234895e-01 -1.19261655e+00 -1.95330158e+00\n",
      "  1.01918354e+00 -6.64302632e-01 -5.84436207e-01]\n",
      "[ 2.02203020e+11  4.07785048e-01  1.33319775e+00  1.07230869e+00\n",
      "  3.88736813e-01 -6.69040526e-01 -5.90265633e-01]\n",
      "[ 2.02203020e+11  1.18680499e+00 -1.82290829e-01 -7.06996327e-02\n",
      "  7.35134518e-02 -5.12690052e-01 -4.38700544e-01]\n",
      "[ 2.02203020e+11  4.07785048e-01  1.33319775e+00  1.81190231e+00\n",
      "  7.03960175e-01 -6.52457900e-01 -5.64033214e-01]\n",
      "[ 2.02210030e+11 -3.71234895e-01 -1.82290829e-01 -4.74114335e-01\n",
      " -5.56933271e-01 -6.60749213e-01 -5.93180347e-01]\n",
      "[ 2.02210030e+11 -3.71234895e-01  8.28034889e-01 -9.44764821e-01\n",
      " -1.50260336e+00 -6.72593945e-01 -5.99009773e-01]\n",
      "[ 2.02210030e+11 -3.71234895e-01  8.28034889e-01 -3.39642767e-01\n",
      "  7.35134518e-02 -6.80885258e-01 -6.10668626e-01]\n",
      "[ 2.02210030e+11 -3.71234895e-01  8.28034889e-01 -1.21370796e+00\n",
      "  7.35134518e-02 -3.71737732e-01 -1.82205778e-01]\n",
      "[ 2.02210030e+11 -1.15025484e+00 -1.82290829e-01 -7.43057470e-01\n",
      "  7.35134518e-02 -6.67856052e-01 -5.90265633e-01]\n",
      "[ 2.02210030e+11 -1.15025484e+00 -1.82290829e-01 -8.77529037e-01\n",
      "  7.35134518e-02 -6.64302632e-01 -6.01924486e-01]\n",
      "[ 2.02210030e+11 -3.71234895e-01 -1.19261655e+00 -1.68435844e+00\n",
      "  1.01918354e+00 -6.57195793e-01 -5.84436207e-01]\n",
      "[ 2.02210030e+11 -3.71234895e-01 -1.19261655e+00  6.68893988e-01\n",
      "  3.88736813e-01 -6.77331839e-01 -6.10668626e-01]\n",
      "[ 2.02210030e+11 -3.71234895e-01 -1.82290829e-01 -4.74114335e-01\n",
      " -1.81782672e+00 -6.52457900e-01 -5.84436207e-01]\n",
      "[ 2.02210030e+11  1.18680499e+00  8.28034889e-01 -3.46384902e-03\n",
      " -2.41709910e-01 -6.00341075e-01 -5.55289074e-01]\n",
      "[ 2.02210030e+11  1.96582493e+00  8.28034889e-01  1.81190231e+00\n",
      " -5.56933271e-01 -6.21661594e-01 -5.52374361e-01]\n",
      "[ 2.02210030e+11  4.07785048e-01  1.33319775e+00  1.07230869e+00\n",
      " -2.41709910e-01 -6.83254205e-01 -6.10668626e-01]\n",
      "[ 2.02202011e+11 -1.15025484e+00 -1.82290829e-01  2.65479286e-01\n",
      "  7.03960175e-01 -6.61933686e-01 -6.04839200e-01]\n",
      "[ 2.02202011e+11 -3.71234895e-01  8.28034889e-01 -1.14647217e+00\n",
      "  7.35134518e-02 -5.97972129e-01 -5.55289074e-01]\n",
      "[ 2.02202011e+11 -3.71234895e-01  8.28034889e-01  6.01658204e-01\n",
      "  1.01918354e+00 -6.54826846e-01 -5.78606780e-01]\n",
      "[ 2.02202011e+11 -3.71234895e-01 -1.82290829e-01 -1.34817952e+00\n",
      " -2.41709910e-01 -5.18612419e-01 -4.44529971e-01]\n",
      "[ 2.02202011e+11 -1.15025484e+00 -1.82290829e-01  2.41702436e+00\n",
      "  7.35134518e-02 -6.89176571e-01 -6.19412766e-01]\n",
      "[ 2.02202011e+11 -3.71234895e-01 -1.82290829e-01  1.54295918e+00\n",
      " -5.56933271e-01 -6.69040526e-01 -5.99009773e-01]\n",
      "[ 2.02202011e+11 -3.71234895e-01 -1.19261655e+00  6.68893988e-01\n",
      "  1.01918354e+00 -6.71409472e-01 -6.16498053e-01]\n",
      "[ 2.02202011e+11 -3.71234895e-01 -1.82290829e-01  1.13954447e+00\n",
      " -1.18737999e+00 -6.59564739e-01 -5.75692067e-01]\n",
      "[ 2.02202011e+11 -3.71234895e-01 -1.19261655e+00 -8.77529037e-01\n",
      "  7.35134518e-02 -6.50088953e-01 -5.81521494e-01]\n",
      "[ 2.02202011e+11  1.96582493e+00  3.22872030e-01 -1.21370796e+00\n",
      "  1.01918354e+00 -3.51601686e-01 -3.71662139e-01]\n",
      "[ 2.02202011e+11  1.18680499e+00  3.22872030e-01 -3.39642767e-01\n",
      "  1.33440690e+00 -5.25719258e-01 -3.94979845e-01]\n",
      "[ 2.02202011e+11 -3.71234895e-01 -2.70810513e+00 -7.06996327e-02\n",
      " -1.50260336e+00 -6.83254205e-01 -6.13583340e-01]\n",
      "[ 2.02203021e+11  2.74484488e+00  2.84868633e+00  2.61873171e+00\n",
      " -2.41709910e-01 -5.52962144e-01 -3.86235706e-01]\n",
      "[ 2.02203021e+11 -3.71234895e-01 -1.82290829e-01 -8.10293253e-01\n",
      "  7.35134518e-02 -6.60749213e-01 -5.78606780e-01]\n",
      "[ 2.02203021e+11 -3.71234895e-01 -1.82290829e-01 -7.43057470e-01\n",
      "  3.88736813e-01 -6.71409472e-01 -6.04839200e-01]\n",
      "[ 2.02203021e+11  2.74484488e+00  2.84868633e+00  7.36129772e-01\n",
      "  7.03960175e-01 -6.61933686e-01 -5.87350920e-01]\n",
      "[ 2.02203021e+11 -1.15025484e+00 -1.82290829e-01 -1.28094374e+00\n",
      "  7.35134518e-02 -6.34690800e-01 -5.81521494e-01]\n",
      "[ 2.02203021e+11 -1.15025484e+00 -1.82290829e-01 -6.75821686e-01\n",
      "  7.35134518e-02 -6.82069732e-01 -6.13583340e-01]\n",
      "[ 2.02203021e+11 -3.71234895e-01 -1.82290829e-01 -9.44764821e-01\n",
      "  1.01918354e+00 -6.74962892e-01 -6.04839200e-01]\n",
      "[ 2.02203021e+11  4.07785048e-01  3.22872030e-01 -8.77529037e-01\n",
      " -8.72156633e-01 -5.11505579e-01 -4.50359397e-01]\n",
      "[ 2.02203021e+11  4.07785048e-01  3.22872030e-01  1.40848761e+00\n",
      "  7.35134518e-02 -3.93058251e-01 -3.77491566e-01]\n",
      "[ 2.02203021e+11 -3.71234895e-01 -1.82290829e-01  8.70601339e-01\n",
      " -2.41709910e-01 -6.87992098e-01 -6.19412766e-01]\n",
      "[ 2.02203021e+11  4.07785048e-01  3.22872030e-01  1.54295918e+00\n",
      "  1.33440690e+00 -6.06263442e-01 -5.31971368e-01]\n",
      "[ 2.02203021e+11 -3.71234895e-01 -2.70810513e+00 -1.48265109e+00\n",
      "  3.88736813e-01 -6.64302632e-01 -5.87350920e-01]\n",
      "[ 2.02210031e+11 -1.15025484e+00 -1.82290829e-01 -7.43057470e-01\n",
      " -8.72156633e-01 -6.66671579e-01 -6.04839200e-01]\n",
      "[ 2.02210031e+11 -3.71234895e-01 -1.82290829e-01  4.67186637e-01\n",
      " -2.41709910e-01 -6.57195793e-01 -5.90265633e-01]\n",
      "[ 2.02210031e+11 -3.71234895e-01 -1.19261655e+00 -8.10293253e-01\n",
      " -5.56933271e-01 -6.45351060e-01 -5.69862641e-01]\n",
      "[ 2.02210031e+11 -3.71234895e-01 -1.82290829e-01 -2.72406984e-01\n",
      "  1.01918354e+00 -6.45351060e-01 -5.58203788e-01]\n",
      "[ 2.02210031e+11 -1.15025484e+00 -1.82290829e-01 -7.43057470e-01\n",
      "  7.35134518e-02 -6.29952907e-01 -5.29056655e-01]\n",
      "[ 2.02210031e+11 -1.15025484e+00 -1.82290829e-01  1.47572339e+00\n",
      "  7.35134518e-02 -6.50088953e-01 -5.99009773e-01]\n",
      "[ 2.02210031e+11 -3.71234895e-01  8.28034889e-01 -7.06996327e-02\n",
      " -1.18737999e+00 -5.20981365e-01 -4.70762390e-01]\n",
      "[ 2.02210031e+11 -3.71234895e-01 -1.82290829e-01  6.01658204e-01\n",
      " -8.72156633e-01 -6.63118159e-01 -5.93180347e-01]\n",
      "[ 2.02210031e+11 -3.71234895e-01 -1.19261655e+00 -1.21370796e+00\n",
      "  1.01918354e+00 -6.77331839e-01 -6.07753913e-01]\n",
      "[ 2.02210031e+11  1.18680499e+00  3.22872030e-01  1.98243502e-01\n",
      " -1.18737999e+00 -5.67175823e-01 -5.08653662e-01]\n",
      "[ 2.02210031e+11  1.18680499e+00  8.28034889e-01  6.68893988e-01\n",
      " -5.56933271e-01 -6.48904480e-01 -5.78606780e-01]\n",
      "[ 2.02210031e+11  1.18680499e+00  3.22872030e-01 -4.06878551e-01\n",
      "  2.59530034e+00 -5.83758449e-01 -4.91165383e-01]\n",
      "[ 2.02202011e+11 -1.15025484e+00 -1.82290829e-01  6.68893988e-01\n",
      " -1.18737999e+00 -6.86807625e-01 -6.22327479e-01]\n",
      "[ 2.02202011e+11 -3.71234895e-01 -1.82290829e-01  8.70601339e-01\n",
      " -5.56933271e-01 -6.60749213e-01 -5.90265633e-01]\n",
      "[ 2.02202011e+11 -3.71234895e-01 -1.82290829e-01 -1.37935416e-01\n",
      "  1.96485362e+00 -5.09136632e-01 -4.44529971e-01]\n",
      "[ 2.02202011e+11 -3.71234895e-01 -1.82290829e-01  6.68893988e-01\n",
      " -5.56933271e-01 -6.83254205e-01 -6.19412766e-01]\n",
      "[ 2.02202011e+11 -3.71234895e-01 -1.82290829e-01 -1.28094374e+00\n",
      " -8.72156633e-01 -5.52962144e-01 -4.47444684e-01]\n",
      "[ 2.02202011e+11 -3.71234895e-01 -2.20294227e+00  2.65479286e-01\n",
      "  1.33440690e+00 -6.31137381e-01 -5.55289074e-01]\n",
      "[ 2.02202011e+11  1.18680499e+00  8.28034889e-01  1.47572339e+00\n",
      "  3.88736813e-01 -6.74962892e-01 -6.04839200e-01]\n",
      "[ 2.02202011e+11 -3.71234895e-01 -1.19261655e+00  6.37719347e-02\n",
      " -2.41709910e-01 -6.19292648e-01 -5.17397802e-01]\n",
      "[ 2.02202011e+11 -3.71234895e-01 -1.82290829e-01 -7.43057470e-01\n",
      "  7.35134518e-02 -6.84438678e-01 -6.19412766e-01]\n",
      "[ 2.02202011e+11 -3.71234895e-01 -1.19261655e+00  7.36129772e-01\n",
      "  1.33440690e+00 -6.59564739e-01 -5.78606780e-01]\n",
      "[ 2.02202011e+11 -1.15025484e+00 -1.82290829e-01  3.99950853e-01\n",
      " -1.18737999e+00 -6.21661594e-01 -5.64033214e-01]\n",
      "[ 2.02202011e+11 -3.71234895e-01 -1.82290829e-01 -1.07923639e+00\n",
      "  7.35134518e-02 -6.29952907e-01 -5.64033214e-01]\n",
      "[ 2.02203021e+11 -1.15025484e+00 -1.82290829e-01  1.31007718e-01\n",
      "  1.01918354e+00 -6.48904480e-01 -5.87350920e-01]\n",
      "[ 2.02203021e+11 -1.15025484e+00 -1.82290829e-01  7.36129772e-01\n",
      "  7.03960175e-01 -6.15739228e-01 -5.46544935e-01]\n",
      "[ 2.02203021e+11 -3.71234895e-01  8.28034889e-01  1.31007718e-01\n",
      "  3.88736813e-01 -6.58380266e-01 -5.66947927e-01]\n",
      "[ 2.02203021e+11 -3.71234895e-01 -1.82290829e-01  7.36129772e-01\n",
      "  1.96485362e+00 -6.65487106e-01 -5.90265633e-01]\n",
      "[ 2.02203021e+11 -1.15025484e+00 -1.82290829e-01 -1.34817952e+00\n",
      "  7.35134518e-02 -4.35699289e-01 -4.15382838e-01]\n",
      "[ 2.02203021e+11 -1.15025484e+00 -1.82290829e-01 -9.44764821e-01\n",
      "  7.35134518e-02 -6.41797640e-01 -5.55289074e-01]\n",
      "[ 2.02203021e+11 -3.71234895e-01  8.28034889e-01 -3.46384902e-03\n",
      "  7.35134518e-02 -6.37059747e-01 -5.61118501e-01]\n",
      "[ 2.02203021e+11 -3.71234895e-01 -1.19261655e+00  4.67186637e-01\n",
      " -5.56933271e-01 -6.00341075e-01 -5.11568376e-01]\n",
      "[ 2.02203021e+11 -3.71234895e-01 -1.19261655e+00 -6.08585902e-01\n",
      " -2.41709910e-01 -6.74962892e-01 -6.07753913e-01]\n",
      "[ 2.02203021e+11 -3.71234895e-01 -1.82290829e-01  2.28255280e+00\n",
      "  2.91052371e+00 -6.89176571e-01 -6.22327479e-01]\n",
      "[ 2.02203021e+11  1.18680499e+00 -1.82290829e-01  1.31007718e-01\n",
      "  7.03960175e-01 -6.21661594e-01 -5.31971368e-01]\n",
      "[ 2.02203021e+11 -3.71234895e-01 -1.82290829e-01  1.00507291e+00\n",
      " -2.41709910e-01 -5.25719258e-01 -4.03723985e-01]\n",
      "[ 2.02210031e+11  4.07785048e-01  2.84868633e+00 -8.10293253e-01\n",
      " -1.50260336e+00 -6.76147365e-01 -5.81521494e-01]\n",
      "[ 2.02210031e+11 -3.71234895e-01 -1.82290829e-01 -6.75821686e-01\n",
      "  7.35134518e-02 -6.73778419e-01 -6.04839200e-01]\n",
      "[ 2.02210031e+11 -1.15025484e+00 -1.82290829e-01 -3.46384902e-03\n",
      " -5.56933271e-01 -6.11001335e-01 -4.70762390e-01]\n",
      "[ 2.02210031e+11 -3.71234895e-01  8.28034889e-01  7.36129772e-01\n",
      " -2.41709910e-01 -6.72593945e-01 -6.04839200e-01]\n",
      "[ 2.02210031e+11 -1.15025484e+00 -1.82290829e-01  3.32715069e-01\n",
      "  7.35134518e-02 -6.32321854e-01 -5.64033214e-01]\n",
      "[ 2.02210031e+11 -3.71234895e-01 -1.82290829e-01 -3.46384902e-03\n",
      " -5.56933271e-01 -6.82069732e-01 -6.19412766e-01]\n",
      "[ 2.02210031e+11 -3.71234895e-01 -1.19261655e+00  4.67186637e-01\n",
      "  3.88736813e-01 -6.60749213e-01 -5.87350920e-01]\n",
      "[ 2.02210031e+11 -3.71234895e-01 -1.82290829e-01  3.32715069e-01\n",
      " -2.41709910e-01 -6.80885258e-01 -6.04839200e-01]\n",
      "[ 2.02210031e+11 -3.71234895e-01 -1.19261655e+00  1.31007718e-01\n",
      " -1.18737999e+00 -5.75467136e-01 -4.15382838e-01]\n",
      "[ 2.02210031e+11 -3.71234895e-01 -1.82290829e-01 -6.75821686e-01\n",
      " -5.56933271e-01 -6.77331839e-01 -6.16498053e-01]\n",
      "[ 2.02210031e+11  4.07785048e-01  1.33319775e+00  1.47572339e+00\n",
      "  3.88736813e-01 -6.06263442e-01 -5.08653662e-01]\n",
      "[ 2.02210031e+11 -3.71234895e-01 -1.82290829e-01  2.68596750e+00\n",
      "  3.88736813e-01 -5.16243472e-01 -4.00809272e-01]\n",
      "[ 2.02202011e+11 -1.15025484e+00 -1.82290829e-01 -7.43057470e-01\n",
      " -5.56933271e-01 -6.27583961e-01 -5.64033214e-01]\n",
      "[ 2.02202011e+11 -3.71234895e-01  8.28034889e-01  5.34422421e-01\n",
      " -8.72156633e-01 -6.39428693e-01 -5.72777354e-01]\n",
      "[ 2.02202011e+11 -3.71234895e-01 -1.82290829e-01 -4.74114335e-01\n",
      " -5.56933271e-01 -5.32826098e-01 -4.12468125e-01]\n",
      "[ 2.02202011e+11 -3.71234895e-01 -1.69777941e+00 -9.44764821e-01\n",
      "  1.33440690e+00 -5.44670831e-01 -4.06638698e-01]\n",
      "[ 2.02202011e+11 -1.15025484e+00 -1.82290829e-01  3.99950853e-01\n",
      "  7.35134518e-02 -1.56163594e-01 -3.22112014e-01]\n",
      "[ 2.02202011e+11 -3.71234895e-01 -1.82290829e-01 -1.41541531e+00\n",
      "  7.03960175e-01 -6.15739228e-01 -5.49459648e-01]\n",
      "[ 2.02202011e+11 -3.71234895e-01 -2.70810513e+00 -6.75821686e-01\n",
      "  3.88736813e-01 -6.31137381e-01 -5.34886082e-01]\n",
      "[ 2.02202011e+11 -3.71234895e-01 -1.82290829e-01  2.41702436e+00\n",
      "  7.03960175e-01 -6.79700785e-01 -6.10668626e-01]\n",
      "[ 2.02202011e+11 -3.71234895e-01 -1.19261655e+00 -6.75821686e-01\n",
      "  3.88736813e-01 -6.85623151e-01 -6.19412766e-01]\n",
      "[ 2.02202011e+11 -3.71234895e-01 -1.82290829e-01  1.13954447e+00\n",
      " -5.56933271e-01 -6.40613167e-01 -5.64033214e-01]\n",
      "[ 2.02202011e+11  1.96582493e+00  1.33319775e+00  4.67186637e-01\n",
      "  7.03960175e-01 -4.81893747e-01 -3.77491566e-01]\n",
      "[ 2.02202011e+11  4.07785048e-01  3.22872030e-01 -3.46384902e-03\n",
      "  7.03960175e-01 -4.34514816e-01 -2.95879595e-01]\n",
      "[ 2.02203021e+11 -1.15025484e+00 -1.82290829e-01 -1.34817952e+00\n",
      "  7.35134518e-02 -6.69040526e-01 -6.04839200e-01]\n",
      "[ 2.02203021e+11 -1.15025484e+00 -1.82290829e-01  3.99950853e-01\n",
      "  3.88736813e-01 -6.44166587e-01 -5.84436207e-01]\n",
      "[ 2.02203021e+11 -3.71234895e-01  8.28034889e-01  1.61019496e+00\n",
      "  7.35134518e-02  1.72359550e+00  1.85517879e+00]\n",
      "[ 2.02203021e+11 -1.15025484e+00 -1.82290829e-01  8.03365555e-01\n",
      "  7.35134518e-02 -6.69040526e-01 -6.07753913e-01]\n",
      "[ 2.02203021e+11 -1.15025484e+00 -1.82290829e-01 -1.01200060e+00\n",
      "  7.35134518e-02 -3.85951411e-01 -4.00809272e-01]\n",
      "[ 2.02203021e+11 -3.71234895e-01 -1.82290829e-01 -2.55842363e+00\n",
      " -1.81782672e+00 -6.14554755e-01 -4.99909523e-01]\n",
      "[ 2.02203021e+11 -3.71234895e-01 -1.19261655e+00  1.47572339e+00\n",
      "  2.59530034e+00 -5.18612419e-01 -3.86235706e-01]\n",
      "[ 2.02203021e+11 -3.71234895e-01 -1.19261655e+00 -6.75821686e-01\n",
      "  7.03960175e-01 -6.25215014e-01 -5.69862641e-01]\n",
      "[ 2.02203021e+11  1.18680499e+00  1.33319775e+00 -5.41350119e-01\n",
      "  7.35134518e-02 -4.94922953e-01 -3.89150419e-01]\n",
      "[ 2.02203021e+11  4.07785048e-01 -6.87453689e-01  3.99950853e-01\n",
      "  1.64963026e+00 -6.60749213e-01 -5.78606780e-01]\n",
      "[ 2.02203021e+11  4.07785048e-01  3.22872030e-01 -1.54988687e+00\n",
      " -8.72156633e-01 -4.91369533e-01 -4.21212265e-01]\n",
      "[ 2.02210031e+11  1.18680499e+00  2.84868633e+00 -2.72406984e-01\n",
      "  7.35134518e-02 -4.23854556e-01 -3.51259147e-01]\n",
      "[ 2.02210031e+11 -1.15025484e+00 -1.82290829e-01  6.68893988e-01\n",
      "  1.96485362e+00 -6.73778419e-01 -6.01924486e-01]\n",
      "[ 2.02210031e+11 -3.71234895e-01  8.28034889e-01  1.20678026e+00\n",
      " -5.56933271e-01 -5.84942923e-01 -5.31971368e-01]\n",
      "[ 2.02210031e+11  3.52386482e+00  2.84868633e+00  1.81190231e+00\n",
      "  7.35134518e-02 -5.89680816e-01 -4.56188824e-01]\n",
      "[ 2.02210031e+11 -1.15025484e+00 -1.82290829e-01  3.32715069e-01\n",
      "  7.35134518e-02 -6.73778419e-01 -6.04839200e-01]\n",
      "[ 2.02210031e+11 -3.71234895e-01 -1.19261655e+00 -7.06996327e-02\n",
      "  7.03960175e-01 -5.62437930e-01 -4.76591817e-01]\n",
      "[ 2.02210031e+11 -3.71234895e-01  8.28034889e-01 -9.44764821e-01\n",
      "  3.88736813e-01 -6.07447915e-01 -5.17397802e-01]\n",
      "[ 2.02210031e+11 -3.71234895e-01 -1.19261655e+00 -2.05171200e-01\n",
      "  3.88736813e-01 -6.52457900e-01 -5.78606780e-01]\n",
      "[ 2.02210031e+11 -3.71234895e-01 -1.82290829e-01  2.08084545e+00\n",
      "  3.88736813e-01 -6.79700785e-01 -6.04839200e-01]\n",
      "[ 2.02210031e+11 -3.71234895e-01 -1.82290829e-01  1.98243502e-01\n",
      "  7.03960175e-01 -6.83254205e-01 -6.19412766e-01]\n",
      "[ 2.02210031e+11  1.18680499e+00  3.22872030e-01 -7.06996327e-02\n",
      "  3.88736813e-01 -6.73778419e-01 -6.10668626e-01]\n",
      "[ 2.02210031e+11 -3.71234895e-01 -1.82290829e-01  6.68893988e-01\n",
      "  1.33440690e+00 -6.40613167e-01 -5.34886082e-01]\n",
      "[ 2.02201010e+11 -1.15025484e+00 -1.82290829e-01 -1.01200060e+00\n",
      "  7.35134518e-02 -6.90361045e-01 -6.22327479e-01]\n",
      "[ 2.02201010e+11 -3.71234895e-01  3.22872030e-01 -4.74114335e-01\n",
      " -2.41709910e-01 -6.13370281e-01 -5.49459648e-01]\n",
      "[ 2.02201010e+11 -3.71234895e-01 -1.82290829e-01 -1.41541531e+00\n",
      "  1.01918354e+00 -6.74962892e-01 -6.19412766e-01]\n",
      "[ 2.02201010e+11 -3.71234895e-01 -1.82290829e-01 -3.46384902e-03\n",
      "  7.03960175e-01 -2.72241976e-01 -2.55073609e-01]\n",
      "[ 2.02201010e+11 -1.15025484e+00 -1.82290829e-01  6.37719347e-02\n",
      "  7.35134518e-02 -5.75467136e-01 -4.99909523e-01]\n",
      "[ 2.02201010e+11 -3.71234895e-01 -1.82290829e-01 -4.74114335e-01\n",
      "  1.01918354e+00 -6.33506327e-01 -5.69862641e-01]\n",
      "[ 2.02201010e+11  4.07785048e-01  3.22872030e-01  6.01658204e-01\n",
      "  1.01918354e+00 -6.48904480e-01 -5.84436207e-01]\n",
      "[ 2.02201010e+11 -3.71234895e-01 -1.82290829e-01  2.65479286e-01\n",
      " -1.50260336e+00 -6.80885258e-01 -6.10668626e-01]\n",
      "[ 2.02201010e+11 -3.71234895e-01 -1.82290829e-01 -2.05171200e-01\n",
      "  7.35134518e-02 -6.69040526e-01 -5.99009773e-01]\n",
      "[ 2.02201010e+11  1.96582493e+00  3.22872030e-01  1.31007718e-01\n",
      " -1.18737999e+00  1.77857871e-01 -3.35554017e-02]\n",
      "[ 2.02201010e+11 -3.71234895e-01 -1.19261655e+00  2.65479286e-01\n",
      "  1.96485362e+00 -6.70224999e-01 -5.93180347e-01]\n",
      "[ 2.02203021e+11  3.52386482e+00  2.84868633e+00  3.99950853e-01\n",
      " -8.72156633e-01 -6.72593945e-01 -5.81521494e-01]\n",
      "[ 2.02203021e+11 -3.71234895e-01  8.28034889e-01  3.99950853e-01\n",
      "  7.03960175e-01 -4.32145869e-01 -3.74576853e-01]\n",
      "[ 2.02203021e+11 -1.15025484e+00 -1.82290829e-01 -8.10293253e-01\n",
      "  7.03960175e-01 -6.69040526e-01 -6.01924486e-01]\n",
      "[ 2.02203021e+11 -3.71234895e-01 -1.82290829e-01 -1.01200060e+00\n",
      " -2.41709910e-01 -6.08632388e-01 -4.47444684e-01]\n",
      "[ 2.02203021e+11 -1.15025484e+00 -1.82290829e-01  7.36129772e-01\n",
      "  7.35134518e-02 -6.73778419e-01 -6.04839200e-01]\n",
      "[ 2.02203021e+11 -1.15025484e+00 -1.82290829e-01 -1.81883001e+00\n",
      "  7.35134518e-02 -6.67856052e-01 -6.01924486e-01]\n",
      "[ 2.02203021e+11 -3.71234895e-01 -6.87453689e-01 -9.44764821e-01\n",
      "  7.03960175e-01 -6.38244220e-01 -5.69862641e-01]\n",
      "[ 2.02203021e+11 -3.71234895e-01 -1.82290829e-01 -9.44764821e-01\n",
      "  3.88736813e-01 -6.15739228e-01 -5.31971368e-01]\n",
      "[ 2.02203021e+11  1.96582493e+00  3.22872030e-01  3.32715069e-01\n",
      " -1.18737999e+00 -2.21309625e-01 -2.78391315e-01]\n",
      "[ 2.02203021e+11 -3.71234895e-01 -1.19261655e+00 -2.15500893e+00\n",
      " -8.72156633e-01 -6.67856052e-01 -6.01924486e-01]\n",
      "[ 2.02203021e+11  1.96582493e+00  8.28034889e-01  6.68893988e-01\n",
      " -5.56933271e-01 -6.52457900e-01 -5.90265633e-01]\n",
      "[ 2.02203021e+11 -3.71234895e-01 -1.19261655e+00 -3.39642767e-01\n",
      "  7.03960175e-01 -6.47720006e-01 -5.81521494e-01]\n",
      "[ 2.02210031e+11 -1.15025484e+00 -6.87453689e-01 -7.06996327e-02\n",
      " -2.13305008e+00 -6.42982113e-01 -5.75692067e-01]\n",
      "[ 2.02210031e+11 -3.71234895e-01 -1.82290829e-01 -1.34817952e+00\n",
      " -5.56933271e-01 -6.54826846e-01 -5.81521494e-01]\n",
      "[ 2.02210031e+11 -3.71234895e-01 -1.82290829e-01 -8.10293253e-01\n",
      " -5.56933271e-01 -6.19292648e-01 -5.11568376e-01]\n",
      "[ 2.02210031e+11 -3.71234895e-01 -1.82290829e-01 -8.77529037e-01\n",
      "  7.35134518e-02 -6.71409472e-01 -5.93180347e-01]\n",
      "[ 2.02210031e+11 -1.15025484e+00 -1.82290829e-01  9.37837123e-01\n",
      "  7.35134518e-02 -6.09816861e-01 -5.66947927e-01]\n",
      "[ 2.02210031e+11 -3.71234895e-01  8.28034889e-01  5.34422421e-01\n",
      "  7.03960175e-01 -6.84438678e-01 -6.19412766e-01]\n",
      "[ 2.02210031e+11 -3.71234895e-01 -1.82290829e-01  4.67186637e-01\n",
      "  7.35134518e-02 -6.44166587e-01 -5.75692067e-01]\n",
      "[ 2.02210031e+11  4.07785048e-01  1.33319775e+00 -7.06996327e-02\n",
      " -8.72156633e-01 -5.87311869e-01 -5.11568376e-01]\n",
      "[ 2.02210031e+11  4.07785048e-01  3.22872030e-01 -1.37935416e-01\n",
      "  7.03960175e-01 -5.30457152e-01 -5.11568376e-01]\n",
      "[ 2.02210031e+11  1.18680499e+00  1.33319775e+00  8.70601339e-01\n",
      " -2.44827344e+00 -5.90865289e-01 -4.91165383e-01]\n",
      "[ 2.02210031e+11  1.18680499e+00  3.22872030e-01  1.74466653e+00\n",
      " -8.72156633e-01 -5.67175823e-01 -4.70762390e-01]\n",
      "[ 2.02210031e+11 -3.71234895e-01 -1.82290829e-01  1.13954447e+00\n",
      "  1.01918354e+00 -6.63118159e-01 -5.75692067e-01]\n",
      "[ 2.02201010e+11 -1.15025484e+00 -1.82290829e-01 -2.08777314e+00\n",
      " -5.56933271e-01 -6.42982113e-01 -5.81521494e-01]\n",
      "[ 2.02201010e+11 -3.71234895e-01 -1.82290829e-01 -3.39642767e-01\n",
      "  7.35134518e-02 -6.29952907e-01 -5.31971368e-01]\n",
      "[ 2.02201010e+11 -3.71234895e-01 -1.82290829e-01 -8.77529037e-01\n",
      " -5.56933271e-01 -6.74962892e-01 -6.13583340e-01]\n",
      "[ 2.02201010e+11 -3.71234895e-01 -6.87453689e-01  1.13954447e+00\n",
      " -8.72156633e-01 -4.33330342e-01 -4.85335956e-01]\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas\n",
    "\n",
    "\n",
    "# パーセプトロンの数\n",
    "N = 4  # 入力層の数\n",
    "K = 20  # 隠れ層の数\n",
    "M = 2  # 出力層の数\n",
    "\n",
    "\n",
    "data = pandas.read_csv(\"std_race_data.csv\")\n",
    "\n",
    "# カラム指定の上列抽出\n",
    "# この時点では\n",
    "# rade_id, horse_age, weight...の行列\n",
    "training_data = data.loc[:, [\"race_id\", \"horse_age\",\n",
    "                             \"weight\", \"hourse_weight\", \"weight_change\", \"single_odds\", \"multi_odds\"]]\n",
    "np_array = training_data.values\n",
    "\n",
    "# mapにばらして、race_idごとに分けていく\n",
    "# つまり\n",
    "# mp[race_id_no1] = [\n",
    "#   [1,2,3,4,5,6],\n",
    "#   [1,2,3,4,5,6],\n",
    "# ]\n",
    "# みたいなデータが出来る\n",
    "# ついでに正解データも作る\n",
    "mp = {}\n",
    "mp_answer = {}\n",
    "for r in np_array:\n",
    "    if r[0] in mp:\n",
    "        mp[r[0]].append(r[1:5].tolist())\n",
    "        mp_answer[r[0]].append(r[5:7].tolist())\n",
    "    else:\n",
    "        mp[r[0]] = []\n",
    "        mp_answer[r[0]] = []\n",
    "        mp[r[0]].append(r[1:5].tolist())\n",
    "        print(r)\n",
    "        mp_answer[r[0]].append(r[5:7].tolist())\n",
    "\n",
    "tmp_data = []\n",
    "tmp_answer = []\n",
    "for key in mp.keys():\n",
    "    tmp_data.append(mp[key])\n",
    "    tmp_answer.append(mp_answer[key])\n",
    "\n",
    "# ちょい怠いので一旦16頭建てのレース以外排除する\n",
    "training_data = []\n",
    "answer_data = []\n",
    "for index in range(0, len(tmp_data)):\n",
    "    if len(tmp_data[index]) == 16:\n",
    "        training_data.append(tmp_data[index])\n",
    "        answer_data.append(tmp_answer[index])\n",
    "\n",
    "trainingList = training_data\n",
    "answerList = answer_data\n",
    "# d = pandas.DataFrame(training_data)\n",
    "# a = pandas.DataFrame(answer_data)\n",
    "# trainingList = d.values\n",
    "# answerList = a.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 16, 20)            100       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 16, 2)             42        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 142\n",
      "Trainable params: 142\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.7856\n",
      "Epoch 2/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.7780\n",
      "Epoch 3/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.7708\n",
      "Epoch 4/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7643\n",
      "Epoch 5/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.7579\n",
      "Epoch 6/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.7511\n",
      "Epoch 7/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.7451\n",
      "Epoch 8/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.7380\n",
      "Epoch 9/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7324\n",
      "Epoch 10/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.7253\n",
      "Epoch 11/256\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7193\n",
      "Epoch 12/256\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7135\n",
      "Epoch 13/256\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7075\n",
      "Epoch 14/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.7021\n",
      "Epoch 15/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6967\n",
      "Epoch 16/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6912\n",
      "Epoch 17/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6861\n",
      "Epoch 18/256\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6809\n",
      "Epoch 19/256\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6755\n",
      "Epoch 20/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6704\n",
      "Epoch 21/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6657\n",
      "Epoch 22/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6608\n",
      "Epoch 23/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6564\n",
      "Epoch 24/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6523\n",
      "Epoch 25/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6482\n",
      "Epoch 26/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6441\n",
      "Epoch 27/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6396\n",
      "Epoch 28/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6355\n",
      "Epoch 29/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6307\n",
      "Epoch 30/256\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6263\n",
      "Epoch 31/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6218\n",
      "Epoch 32/256\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6176\n",
      "Epoch 33/256\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6134\n",
      "Epoch 34/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6090\n",
      "Epoch 35/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6045\n",
      "Epoch 36/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6003\n",
      "Epoch 37/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5961\n",
      "Epoch 38/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5920\n",
      "Epoch 39/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5880\n",
      "Epoch 40/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5844\n",
      "Epoch 41/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5806\n",
      "Epoch 42/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5773\n",
      "Epoch 43/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5736\n",
      "Epoch 44/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5700\n",
      "Epoch 45/256\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5665\n",
      "Epoch 46/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5628\n",
      "Epoch 47/256\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5593\n",
      "Epoch 48/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5557\n",
      "Epoch 49/256\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5523\n",
      "Epoch 50/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5490\n",
      "Epoch 51/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5458\n",
      "Epoch 52/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5425\n",
      "Epoch 53/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5393\n",
      "Epoch 54/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5363\n",
      "Epoch 55/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5333\n",
      "Epoch 56/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5304\n",
      "Epoch 57/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5275\n",
      "Epoch 58/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5249\n",
      "Epoch 59/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5221\n",
      "Epoch 60/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5193\n",
      "Epoch 61/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5168\n",
      "Epoch 62/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5140\n",
      "Epoch 63/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5113\n",
      "Epoch 64/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5086\n",
      "Epoch 65/256\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5057\n",
      "Epoch 66/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5029\n",
      "Epoch 67/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5000\n",
      "Epoch 68/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4972\n",
      "Epoch 69/256\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4942\n",
      "Epoch 70/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4915\n",
      "Epoch 71/256\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4888\n",
      "Epoch 72/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4862\n",
      "Epoch 73/256\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4836\n",
      "Epoch 74/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4813\n",
      "Epoch 75/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4789\n",
      "Epoch 76/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4765\n",
      "Epoch 77/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4741\n",
      "Epoch 78/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4716\n",
      "Epoch 79/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4691\n",
      "Epoch 80/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4667\n",
      "Epoch 81/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4645\n",
      "Epoch 82/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4621\n",
      "Epoch 83/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4601\n",
      "Epoch 84/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4578\n",
      "Epoch 85/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4557\n",
      "Epoch 86/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4535\n",
      "Epoch 87/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4509\n",
      "Epoch 88/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4485\n",
      "Epoch 89/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4459\n",
      "Epoch 90/256\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4433\n",
      "Epoch 91/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4407\n",
      "Epoch 92/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4381\n",
      "Epoch 93/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4354\n",
      "Epoch 94/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4330\n",
      "Epoch 95/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4302\n",
      "Epoch 96/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4279\n",
      "Epoch 97/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4255\n",
      "Epoch 98/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4229\n",
      "Epoch 99/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4203\n",
      "Epoch 100/256\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4179\n",
      "Epoch 101/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4154\n",
      "Epoch 102/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4127\n",
      "Epoch 103/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4104\n",
      "Epoch 104/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4078\n",
      "Epoch 105/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4054\n",
      "Epoch 106/256\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4029\n",
      "Epoch 107/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4008\n",
      "Epoch 108/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.3985\n",
      "Epoch 109/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.3965\n",
      "Epoch 110/256\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3944\n",
      "Epoch 111/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3926\n",
      "Epoch 112/256\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3908\n",
      "Epoch 113/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.3890\n",
      "Epoch 114/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3873\n",
      "Epoch 115/256\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3857\n",
      "Epoch 116/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3841\n",
      "Epoch 117/256\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3826\n",
      "Epoch 118/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3812\n",
      "Epoch 119/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3798\n",
      "Epoch 120/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.3785\n",
      "Epoch 121/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3772\n",
      "Epoch 122/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.3758\n",
      "Epoch 123/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3745\n",
      "Epoch 124/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.3731\n",
      "Epoch 125/256\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3716\n",
      "Epoch 126/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.3704\n",
      "Epoch 127/256\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3688\n",
      "Epoch 128/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.3676\n",
      "Epoch 129/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.3662\n",
      "Epoch 130/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.3649\n",
      "Epoch 131/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3634\n",
      "Epoch 132/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.3620\n",
      "Epoch 133/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.3607\n",
      "Epoch 134/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3594\n",
      "Epoch 135/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.3582\n",
      "Epoch 136/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3568\n",
      "Epoch 137/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.3555\n",
      "Epoch 138/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3541\n",
      "Epoch 139/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3525\n",
      "Epoch 140/256\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3511\n",
      "Epoch 141/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3497\n",
      "Epoch 142/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3481\n",
      "Epoch 143/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.3466\n",
      "Epoch 144/256\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3454\n",
      "Epoch 145/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.3442\n",
      "Epoch 146/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.3431\n",
      "Epoch 147/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.3420\n",
      "Epoch 148/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3413\n",
      "Epoch 149/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3402\n",
      "Epoch 150/256\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3393\n",
      "Epoch 151/256\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3382\n",
      "Epoch 152/256\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3375\n",
      "Epoch 153/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3366\n",
      "Epoch 154/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.3356\n",
      "Epoch 155/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.3348\n",
      "Epoch 156/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.3338\n",
      "Epoch 157/256\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3328\n",
      "Epoch 158/256\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3319\n",
      "Epoch 159/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3309\n",
      "Epoch 160/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3299\n",
      "Epoch 161/256\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3288\n",
      "Epoch 162/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.3277\n",
      "Epoch 163/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3267\n",
      "Epoch 164/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.3258\n",
      "Epoch 165/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3248\n",
      "Epoch 166/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3239\n",
      "Epoch 167/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.3230\n",
      "Epoch 168/256\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3220\n",
      "Epoch 169/256\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3212\n",
      "Epoch 170/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3202\n",
      "Epoch 171/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3194\n",
      "Epoch 172/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.3185\n",
      "Epoch 173/256\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3177\n",
      "Epoch 174/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3168\n",
      "Epoch 175/256\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3158\n",
      "Epoch 176/256\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3150\n",
      "Epoch 177/256\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3141\n",
      "Epoch 178/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.3132\n",
      "Epoch 179/256\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3124\n",
      "Epoch 180/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.3116\n",
      "Epoch 181/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3109\n",
      "Epoch 182/256\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3102\n",
      "Epoch 183/256\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3093\n",
      "Epoch 184/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3085\n",
      "Epoch 185/256\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3079\n",
      "Epoch 186/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3072\n",
      "Epoch 187/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3065\n",
      "Epoch 188/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3058\n",
      "Epoch 189/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3052\n",
      "Epoch 190/256\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3043\n",
      "Epoch 191/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.3038\n",
      "Epoch 192/256\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3029\n",
      "Epoch 193/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.3022\n",
      "Epoch 194/256\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3017\n",
      "Epoch 195/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3010\n",
      "Epoch 196/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3005\n",
      "Epoch 197/256\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2999\n",
      "Epoch 198/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2995\n",
      "Epoch 199/256\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2989\n",
      "Epoch 200/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.2982\n",
      "Epoch 201/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.2975\n",
      "Epoch 202/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2969\n",
      "Epoch 203/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2962\n",
      "Epoch 204/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2956\n",
      "Epoch 205/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2951\n",
      "Epoch 206/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2945\n",
      "Epoch 207/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.2940\n",
      "Epoch 208/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.2935\n",
      "Epoch 209/256\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2930\n",
      "Epoch 210/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2925\n",
      "Epoch 211/256\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2921\n",
      "Epoch 212/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.2916\n",
      "Epoch 213/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.2913\n",
      "Epoch 214/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.2909\n",
      "Epoch 215/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2905\n",
      "Epoch 216/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2901\n",
      "Epoch 217/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2896\n",
      "Epoch 218/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.2892\n",
      "Epoch 219/256\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.2885\n",
      "Epoch 220/256\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.2880\n",
      "Epoch 221/256\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2876\n",
      "Epoch 222/256\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2869\n",
      "Epoch 223/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2866\n",
      "Epoch 224/256\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2860\n",
      "Epoch 225/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2856\n",
      "Epoch 226/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.2851\n",
      "Epoch 227/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.2846\n",
      "Epoch 228/256\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2842\n",
      "Epoch 229/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2838\n",
      "Epoch 230/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.2833\n",
      "Epoch 231/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.2829\n",
      "Epoch 232/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2826\n",
      "Epoch 233/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.2822\n",
      "Epoch 234/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.2818\n",
      "Epoch 235/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.2815\n",
      "Epoch 236/256\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.2810\n",
      "Epoch 237/256\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2807\n",
      "Epoch 238/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2803\n",
      "Epoch 239/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2799\n",
      "Epoch 240/256\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2795\n",
      "Epoch 241/256\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2791\n",
      "Epoch 242/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.2789\n",
      "Epoch 243/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2785\n",
      "Epoch 244/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2783\n",
      "Epoch 245/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.2779\n",
      "Epoch 246/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2774\n",
      "Epoch 247/256\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2771\n",
      "Epoch 248/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2768\n",
      "Epoch 249/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2764\n",
      "Epoch 250/256\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2762\n",
      "Epoch 251/256\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2759\n",
      "Epoch 252/256\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2758\n",
      "Epoch 253/256\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.2756\n",
      "Epoch 254/256\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2755\n",
      "Epoch 255/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2754\n",
      "Epoch 256/256\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2753\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/tomoyan/horse-fire/env/lib/python3.8/site-packages/keras/engine/training.py\", line 2041, in predict_function  *\n        return step_function(self, iterator)\n    File \"/home/tomoyan/horse-fire/env/lib/python3.8/site-packages/keras/engine/training.py\", line 2027, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/tomoyan/horse-fire/env/lib/python3.8/site-packages/keras/engine/training.py\", line 2015, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/home/tomoyan/horse-fire/env/lib/python3.8/site-packages/keras/engine/training.py\", line 1983, in predict_step\n        return self(x, training=False)\n    File \"/home/tomoyan/horse-fire/env/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/tomoyan/horse-fire/env/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_3\" is incompatible with the layer: expected shape=(None, 16, 4), found shape=(None, 2, 4)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [13], line 60\u001b[0m\n\u001b[1;32m     57\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(trainingList, answerList, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m256\u001b[39m)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# 出力 ※ 戻り値は numpy 配列\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m y \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(testingList)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m入力\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     63\u001b[0m tf\u001b[38;5;241m.\u001b[39mprint(testingList)\n",
      "File \u001b[0;32m~/horse-fire/env/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filemon_r4yy.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/tomoyan/horse-fire/env/lib/python3.8/site-packages/keras/engine/training.py\", line 2041, in predict_function  *\n        return step_function(self, iterator)\n    File \"/home/tomoyan/horse-fire/env/lib/python3.8/site-packages/keras/engine/training.py\", line 2027, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/tomoyan/horse-fire/env/lib/python3.8/site-packages/keras/engine/training.py\", line 2015, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/home/tomoyan/horse-fire/env/lib/python3.8/site-packages/keras/engine/training.py\", line 1983, in predict_step\n        return self(x, training=False)\n    File \"/home/tomoyan/horse-fire/env/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/tomoyan/horse-fire/env/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_3\" is incompatible with the layer: expected shape=(None, 16, 4), found shape=(None, 2, 4)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 入力データ\n",
    "\n",
    "# 学習データ(名前,騎手,会場など)\n",
    "# trainingList = np.array([\n",
    "#     [\n",
    "#         [-0.6879920980515413, -0.6194127660107818, 0.1234, -0.1234],\n",
    "#         [-0.6358752736489328, -0.5028242358046408, 0.1234, -0.1234]\n",
    "#     ],\n",
    "#     [\n",
    "#         [-0.6879920980515413, -0.6194127660107818, 0.1234, -0.1234],\n",
    "#         [-0.6358752736489328, -0.5028242358046408, 0.1234, -0.1234]\n",
    "#     ]\n",
    "# ])\n",
    "\n",
    "# 教師データ(単勝オッズ、複勝オッズ)\n",
    "# answerList = np.array([\n",
    "#     [\n",
    "#         [0.9, 0.3],\n",
    "#         [0.3, 0.1]\n",
    "#     ],\n",
    "#     [\n",
    "#         [0.9, 0.3],\n",
    "#         [0.3, 0.1]\n",
    "#     ]\n",
    "# ])\n",
    "\n",
    "# テストデータ\n",
    "# データ構造は学習データと同じ。学習済モデルの精度を上げるために必要\n",
    "# testingList = np.array([\n",
    "#     [\n",
    "#         [-0.6879920980515413, -0.6194127660107818, 0.1234, -0.1234],\n",
    "#         [-0.6358752736489328, -0.5028242358046408, 0.1234, -0.1234]\n",
    "#     ],\n",
    "#     [\n",
    "#         [-0.6879920980515413, -0.6194127660107818, 0.1234, -0.1234],\n",
    "#         [-0.6358752736489328, -0.5028242358046408, 0.1234, -0.1234]\n",
    "#     ]\n",
    "# ])\n",
    "\n",
    "\n",
    "# 3層ニューラルネットワークの構築\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.Input(shape=(16, 4)))\n",
    "model.add(tf.keras.layers.Dense(K, activation='tanh'))\n",
    "model.add(tf.keras.layers.Dense(M, activation='softmax'))\n",
    "\n",
    "#  fitするためにコンパイルする\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    ")\n",
    "\n",
    "# モデルの概要表示\n",
    "model.summary()\n",
    "\n",
    "# 固定回数（データセットの反復）の試行でモデルを学習\n",
    "model.fit(trainingList, answerList, None, 256)\n",
    "\n",
    "# 出力 ※ 戻り値は numpy 配列\n",
    "y = model.predict(testingList)\n",
    "\n",
    "print('入力')\n",
    "tf.print(testingList)\n",
    "print('\\n出力')\n",
    "print(y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8d8575a6bee98e76f26a29f0d400338bd3c3729f285ddaedd0291b8d5cb1f262"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
